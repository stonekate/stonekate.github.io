<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Kate Stone | University of Hull</title>
    <link>/blog/</link>
    <description>Recent content in Blog on Kate Stone | University of Hull</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 18 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Tutorial: An RSVP experiment in OpenSesame</title>
      <link>/blog/opensesame/</link>
      <pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>/blog/opensesame/</guid>
      <description>OpenSesame is a free, open source tool for building experiments. In this tutorial, I build a rapid serial visual presentation (RSVP) paradigm of the kind typically used for presenting sentences word-by-word to participants in ERP experiments. The paradigm will send triggers at particular words to the EEG recording computer so that these words can later be located in the EEG recording.
You will need to have OpenSesame installed: https://osdoc.cogsci.nl. There are also several tutorials on that page.</description>
    </item>
    
    <item>
      <title>Bayesian divergence point analysis of visual world data</title>
      <link>/blog/bpda/</link>
      <pubDate>Thu, 08 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/bpda/</guid>
      <description>The visual world is a useful paradigm in psycholinguistics for tracking peopleâ€™s eye fixations as they listen to sentences containing some kind of experimental manipulation. A common question is whether the experimental manipulation makes people look at a target object earlier in one condition than another. To answer this, we need to decide when in each condition people start looking at the target and compare these timepoints between conditions.</description>
    </item>
    
  </channel>
</rss>
